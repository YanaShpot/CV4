{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport cv2\nprint('OpenCV version used:', cv2.__version__)\n\nfrom skimage import io\nfrom matplotlib import pyplot as plt\nimport matplotlib as mpl\nmpl.rcParams['figure.figsize'] = (10,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Affine Transformation: Task 1.2\n- Given 3 pairs of points ﬁnd afﬁne transformation and apply it to an image.\n- Compare with OpenCV function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def url_to_image(url):\n    print(\"downloading %s\" % (url))\n    return io.imread(url)\n\ndef imshow(img, cmap='gray', sub=None, title=None, ax='off'):\n    if sub is not None:\n        plt.subplot(*sub)\n    if title is None:\n        title = img.shape\n    plt.title(title)\n    plt.imshow(img, cmap=cmap)\n    plt.grid(False)\n    plt.axis(ax)\n    if sub is None:\n        plt.show()\n\nurl = \"https://raw.githubusercontent.com/ucuapps/computer-vision-course/master/module4-geometry/practice2_homography/img/view.jpg\"\nimg = url_to_image(url)[:500,:,:]\nimshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Synthesize point correspondences {x1 <-> x2}\n\n(h, w) = img.shape[:2]\n\nx1 = np.float32([[0, 0],\n                 [w, 0],\n                 [0, h]])\n\nx2 = np.float32([[50 ,0],\n                 [w, 50],\n                 [0, h - 50]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get affine transformation with OpenCV\n\nA = cv2.getAffineTransform(x1, x2)\nprint(A)\n\ndst = cv2.warpAffine(img, A, (w,h))\nimshow(img, sub=(1,2,1))\nimshow(dst, sub=(1,2,2))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[],"trusted":true},"cell_type":"code","source":"def getAffineTransform(x1, x2):\n\n#def getAffineTransform(original_points, transformed_points):\n    p = []\n    for x,y in x1:\n        p.append((x,y,1))\n    return np.linalg.solve(p, x2).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A2 = getAffineTransform(x1, x2)\nprint(A2)\n\nassert(np.linalg.norm(A2 - A, 'fro') < 1e-12)\n\ndst = cv2.warpAffine(img, A2, (w,h))\nimshow(img, sub=(1,2,1))\nimshow(dst, sub=(1,2,2))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Projective Transformation: Task 2.2\n- Given 4 pairs of points find projective transformation and apply it to an image. \n- Compare with OpenCV function"},{"metadata":{"trusted":true},"cell_type":"code","source":"url = \"https://raw.githubusercontent.com/ucuapps/computer-vision-course/master/module4-geometry/practice2_homography/img/cvbook.jpg\"\nimg = url_to_image(url)\nimshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get point correspondences {x1 <-> x2}\n\nx1 = np.float32([[241, 6],\n                 [726, 29],\n                 [6, 668],\n                 [627, 837]])\n\nx2 = np.float32([[0, 0],\n                 [300, 0],\n                 [0, 400],\n                 [300, 400]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get homography with OpenCV\n\nH = cv2.getPerspectiveTransform(x1, x2)\nH /= H[2,2]\nprint(H)\n\ndst = cv2.warpPerspective(img, H, (300,400))\nimshow(img, sub=(1,2,1))\nimshow(dst, sub=(1,2,2))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_coef(a, b, n):\n    res = []\n    b = [b[0], b[1], 1]\n    dim = 3\n    for i in range(dim):\n        curr = [0] * dim * 4\n        curr[i] = a[0]\n        curr[dim + i] = a[1]\n        curr[2*dim + i] = 1 if i != 2 else 0\n        \n        curr[3*dim + n - 1] = -b[i]\n        res.append(curr)\n        \n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def getPerspectiveTransform(x1,x2):\ndef getPerspectiveTransform(pts1, pts2):\n    A = []\n    plen = len(pts1)\n    for i in range(plen):\n        A += get_coef(pts1[i], pts2[i], i)\n        \n    B = [0, 0, -1] * plen\n    C = np.linalg.solve(A, B)\n    res = np.ones(9)\n    res[:8] = C.flatten()[:8]\n    return res.reshape(3,-1).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"H2 = getPerspectiveTransform(x1, x2)\nH2 /= H2[2,2]\nprint(H2)\nassert(np.linalg.norm(H2 - H, 'fro') < 1e-12)\n\ndst = cv2.warpPerspective(img, H2, (300, 400))\nimshow(img, sub=(1,2,1))\nimshow(dst, sub=(1,2,2))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correspondence and Matching: Task 3.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"url1 = \"https://raw.githubusercontent.com/ucuapps/computer-vision-course/master/module4-geometry/practice2_homography/img/bookflat.jpg\"\nurl2 = \"https://raw.githubusercontent.com/ucuapps/computer-vision-course/master/module4-geometry/practice2_homography/img/cvbook.jpg\"\nimg1 = cv2.resize(url_to_image(url1), (0,0), fx=0.5, fy=0.5)\nimg2 = cv2.resize(url_to_image(url2), (0,0), fx=0.5, fy=0.5)\nimshow(img1, sub=(1,2,1))\nimshow(img2, sub=(1,2,2))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# \n\norb = cv2.ORB_create()\n# find the keypoints and descriptors with ORB\n# because SIFT and SUFT are patented (Anticipated expiration 2020-03-06)\nkp1, des1 = orb.detectAndCompute(img1, None)\nkp2, des2 = orb.detectAndCompute(img2, None)\n\n# create BFMatcher object (Brute-force descriptor matcher)\nbf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n\n# Match descriptors.\nmatches = bf.match(des1,des2)\n\n# Sort them in the order of their distance.\nmatches = sorted(matches, key = lambda x:x.distance)\n\n# Draw first 30 matches.\nimg3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:30], None, flags=2)\n\nimshow(img3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get homography with OpenCV\n\nif len(matches)>4:\n    src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n\n    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n    matchesMask = mask.ravel().tolist()\n\n    h,w = img1.shape[:2]\n    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n    dst = cv2.perspectiveTransform(pts, H)\n\n    img4 = cv2.polylines(img2, [np.int32(dst)],True,255,3, cv2.LINE_AA)\n    img4_rectified = cv2.warpPerspective(img4, np.linalg.inv(H), (150, 200))\n    imshow(img4, sub=(1,2,1))\n    imshow(img4_rectified, sub=(1,2,2))\n    plt.show()\n\nelse:\n    print(\"Not enough matches are found - %d/%d\" % (len(matches), MIN_MATCH_COUNT))\n    matchesMask = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def findHomography(x1, x2):\n    ########### please implement me ###########\n    pass\n    ###########################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if len(matches)>4:\n    src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n\n    H, mask = findHomography(src_pts, dst_pts)\n    matchesMask = mask.ravel().tolist()\n\n    h,w = img1.shape[:2]\n    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n    dst = cv2.perspectiveTransform(pts, H)\n\n    img4 = cv2.polylines(img2, [np.int32(dst)],True,255,3, cv2.LINE_AA)\n    img4_rectified = cv2.warpPerspective(img4, np.linalg.inv(H), (150, 200))\n    imshow(img4, sub=(1,2,1))\n    imshow(img4_rectified, sub=(1,2,2))\n    plt.show()\n\nelse:\n    print(\"Not enough matches are found - %d/%d\" % (len(matches), MIN_MATCH_COUNT))\n    matchesMask = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false}},"nbformat":4,"nbformat_minor":1}